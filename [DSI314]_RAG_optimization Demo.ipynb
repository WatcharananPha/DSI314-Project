{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kax8gwzp2149"
   },
   "outputs": [],
   "source": [
    "# requirements = [\n",
    "#     \"langchain\",\n",
    "#     \"langchain-community\",\n",
    "#     \"llama-parse\",\n",
    "#     \"fastembed\",\n",
    "#     \"python-dotenv\",\n",
    "#     \"langchain-groq\",\n",
    "#     \"chainlit\",\n",
    "#     \"sentence-transformers\",\n",
    "#     \"openai\",\n",
    "#     \"langchain-openai\",\n",
    "#     \"nltk\",\n",
    "#     \"joblib\",\n",
    "#     \"gdown\",\n",
    "#     \"PyPDF2\",\n",
    "#     \"faiss-cpu\",\n",
    "#     \"nest-asyncio\",\n",
    "#     \"unstructured[md]\"\n",
    "# ]\n",
    "\n",
    "# file_path = \"requirements.txt\"\n",
    "# with open(file_path, \"w\") as f:\n",
    "#     for package in requirements:\n",
    "#         f.write(f\"{package}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3ivk3CKTUXs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple, List, Dict\n",
    "from pypdf import PdfReader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from openai import OpenAI\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "from collections import deque\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "id": "YUXHlcBhR7YK"
   },
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# from PyPDF2 import PdfReader\n",
    "\n",
    "# file_ids = [\n",
    "#     '1ohQ7aQCiY4pKqkKl0_FssgYkkHmeYDWN',\n",
    "#     '1SjDi9aY8_jQtDfe5wix-aFYuS5TP0pDG'\n",
    "# ]\n",
    "\n",
    "# for file_id in file_ids:\n",
    "#     file_url = f'https://drive.googlea.com/uc?id={file_id}'\n",
    "#     output_pdf = f'/content/{file_id}.pdf'\n",
    "#     gdown.download(file_url, output_pdf, quiet=False)\n",
    "#     reader = PdfReader(output_pdf)\n",
    "\n",
    "#     for page_num in range(len(reader.pages)):\n",
    "#         page = reader.pages[page_num]\n",
    "#         print(f\"Text from page {page_num + 1}:\\n{page.extract_text()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "iJh3in61TBo_"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data\"\n",
    "PARSED_DATA_FILE = os.path.join(DATA_DIR, \"parsed_data.pkl\")\n",
    "PDF_FILE = [\n",
    "    'Data\\\\แผนปฏิบัติการการพัฒนาเมืองอุตสาหกรรมเชิงนิเวศพื้นที่ลาดหลุมแก้ว ระยะ 5 ปี (พศ-2566-2570).pdf',\n",
    "    'Data\\\\รายงานการวิเคราะห์อุปสงค์และอุปทานจังหวัด.pdf'\n",
    "]\n",
    "\n",
    "def extract_text_from_pdf(pdf_file: str) -> str:\n",
    "    reader = PdfReader(pdf_file)\n",
    "    all_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        all_text += page.extract_text()\n",
    "    return all_text\n",
    "\n",
    "def create_vector_database(\n",
    "    llamaparse_api_key: str,\n",
    "    pdf_files: list = PDF_FILE,\n",
    "    data_file: str = PARSED_DATA_FILE,\n",
    ") -> Tuple:\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    all_text = \"\"\n",
    "    for pdf_file in pdf_files:\n",
    "        all_text += extract_text_from_pdf(pdf_file)\n",
    "\n",
    "    text_output = os.path.join(DATA_DIR, \"extracted_text.txt\")\n",
    "    with open(text_output, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(all_text)\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=128)\n",
    "    chunks = text_splitter.split_text(all_text)\n",
    "    documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "    embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\") #BAAI/bge-base-en-v1.5\n",
    "    vector_store = FAISS.from_documents(documents=documents, embedding=embed_model)\n",
    "    \n",
    "    faiss_index_path = os.path.join(DATA_DIR, \"faiss_index\")\n",
    "    vector_store.save_local(faiss_index_path)\n",
    "\n",
    "    return vector_store, embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CGfAW41WW-SQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kongl\\AppData\\Local\\Temp\\ipykernel_21196\\141400966.py:32: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\") #BAAI/bge-base-en-v1.5\n",
      "c:\\Users\\kongl\\Documents\\DSI314 Progress 2\\DSI314\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "    api_key='sk-GqA4Uj6iZXaykbOzIlFGtmdJr6VqiX94NhhjPZaf81kylRzh',\n",
    "    base_url='https://api.opentyphoon.ai/v1'\n",
    ")\n",
    "\n",
    "def summarize_text(text, max_tokens=5000):\n",
    "    tokens = text.split()\n",
    "    return ' '.join(tokens[:max_tokens]) + '...' if len(tokens) > max_tokens else text\n",
    "\n",
    "class ConversationalMemory:\n",
    "    def __init__(self, max_length=10):\n",
    "        self.history = deque(maxlen=max_length)\n",
    "    def add_to_memory(self, question: str, response: str | None):\n",
    "        if response is not None :\n",
    "            self.history.append({\"question\": question, \"response\": response})\n",
    "    def get_memory(self) -> List[Dict[str, str]]:\n",
    "        return list(self.history)\n",
    "    def save_memory_to_file(self, file_path: str):\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.get_memory(), f, indent=4)\n",
    "    def load_memory_from_file(self, file_path: str):\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                self.history = deque(json.load(f), maxlen=self.history.maxlen)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"No existing memory file found at {file_path}. Starting fresh.\")\n",
    "\n",
    "def generate_response(prompt):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=\"typhoon-v1.5x-70b-instruct\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "def retrieve_documents(query, retriever):\n",
    "    return retriever.get_relevant_documents(query)\n",
    "\n",
    "def ask_question_with_memory(retriever, question, memory: ConversationalMemory):\n",
    "    retrieved_docs = retrieve_documents(question, retriever)\n",
    "    summarized_data = summarize_text(\"\\n\".join([doc.page_content for doc in retrieved_docs]), max_tokens=5000)\n",
    "    history_context = \"\\n\".join(\n",
    "        [f\"Q: {entry['question']}\\nA: {entry['response']}\" for entry in memory.get_memory()]\n",
    "    )\n",
    "    full_prompt = (\n",
    "        f\"Conversation history:\\n{history_context}\\n\\n\"\n",
    "        f\"Context for Pathum Thani development:\\n{summarized_data}\\n\\n\"\n",
    "        f\"New question: {question}\"\n",
    "    )\n",
    "    response = generate_response(full_prompt)\n",
    "    memory.add_to_memory(question, response)\n",
    "\n",
    "    return response\n",
    "\n",
    "llamaparse_api_key = \"llx-pNes5rGZru1FvO1nINQMrAJMEso0OEWutgy8ejbGntSxNPeq\"\n",
    "vector_db, embed_model = create_vector_database(llamaparse_api_key)\n",
    "\n",
    "retriever = vector_db.as_retriever(search_kwargs={'k': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ll708H0LF22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: # ข้อมูลเกี่ยวกับการพัฒนาด้าน OTOP\n",
      "\n",
      "## OTOP ในจังหวัดปทุมธานี\n",
      "\n",
      "OTOP หรือ One Tambon One Product เป็นโครงการที่ส่งเสริมการผลิตสินค้าและบริการของชุมชนในแต่ละตำบล เพื่อสร้างรายได้และสร้างความเข้มแข็งให้กับชุมชน\n",
      "\n",
      "## สินค้า OTOP ที่โดดเด่น\n",
      "\n",
      "1. ผ้าไหม: จังหวัดปทุมธานีมีชื่อเสียงในการผลิตผ้าไหมที่มีคุณภาพสูง\n",
      "2. ผลิตภัณฑ์จากไม้: จังหวัดปทุมธานีมีทรัพยากรไม้ที่อุดมสมบูรณ์ ทำให้สามารถผลิตผลิตภัณฑ์จากไม้ได้หลากหลายชนิด\n",
      "3. ผลิตภัณฑ์จากดอกไม้: จังหวัดปทุมธานีมีดอกไม้ที่สวยงามและหลากหลายชนิด ทำให้สามารถผลิตผลิตภัณฑ์จากดอกไม้ได้หลากหลายชนิด\n",
      "\n",
      "## การส่งเสริม OTOP\n",
      "\n",
      "1. การฝึกอบรม: รัฐบาลได้จัดโครงการฝึกอบรมให้กับผู้ประกอบการ OTOP เพื่อพัฒนาทักษะและความรู้ในการผลิตสินค้า\n",
      "2. การสนับสนุนเงินทุน: รัฐบาลได้จัดโครงการสนับสนุนเงินทุนให้กับผู้ประกอบการ OTOP เพื่อช่วยเหลือในการลงทุนและขยายกิจการ\n",
      "3. การประชาสัมพันธ์: รัฐบาลได้จัดโครงการประชาสัมพันธ์เพื่อสร้างความตระหนักและสร้างความสนใจในสินค้า OTOP\n",
      "\n",
      "Reference(s):\n",
      "[1] สำนักงานพัฒนาชุมชนจังหวัดปทุมธานี. (2564). รายงานผลการดำเนินงานโครงการ OTOP ปี 2564.\n",
      "[2] สำนักงานพัฒนาชุมชนจังหวัดปทุมธานี. (2565). รายงานผลการดำเนินงานโครงการ OTOP ปี 2565.\n",
      "Answer: # ธุรกิจที่มีแนวโน้มเติบโตมากที่สุดในปทุมธานี\n",
      "\n",
      "## อุตสาหกรรมที่มีแนวโน้มเติบโต\n",
      "\n",
      "อุตสาหกรรมที่มีแนวโน้มเติบโตมากที่สุดในปทุมธานี ได้แก่:\n",
      "\n",
      "1. ศิลปะ ความบันเทิง\n",
      "2. เกษตรกรรม\n",
      "3. คหกรรม\n",
      "\n",
      "## จำนวนผู้ทำงาน\n",
      "\n",
      "จำนวนผู้ทำงานในอุตสาหกรรมที่มีแนวโน้มเติบโตมากที่สุดในปทุมธานี ได้แก่:\n",
      "\n",
      "1. ศิลปะ ความบันเทิง: 7 คน\n",
      "2. เกษตรกรรม: 3 คน\n",
      "3. คหกรรม: 3 คน\n",
      "\n",
      "## อัตราการเติบโต\n",
      "\n",
      "อัตราการเติบโตของอุตสาหกรรมที่มีแนวโน้มเติบโตมากที่สุดในปทุมธานี ได้แก่:\n",
      "\n",
      "1. ศิลปะ ความบันเทิง: ร้อยละ 5.2\n",
      "2. เกษตรกรรม: ร้อยละ 4.2\n",
      "3. คหกรรม: ร้อยละ 4.1\n",
      "\n",
      "Reference(s):\n",
      "[1] รายงานผลการวิเคราะห์ข้อมูลอุปสงค์และอุปทานแรงงาน จังหวัดปทุมธานี พ.ศ. 2566, ตารางที่ 21.\n",
      "Answer: # แรงงานออกจากงานในจังหวัดปทุมธานี\n",
      "\n",
      "## จำนวนแรงงานออกจากงาน\n",
      "\n",
      "จำนวนแรงงานที่ออกจากงานมากที่สุดอยู่ในระดับวุฒิการศึกษาระดับต่ำกว่ามัธยมศึกษาปีที่ 3, มัธยมศึกษาปีที่ 3, และปริญญาตรี ตามลำดับ.\n",
      "\n",
      "## ประเภทอุตสาหกรรมที่มีการออกจากงานจำนวนมากที่สุด\n",
      "\n",
      "ประเภทอุตสาหกรรมที่มีการออกจากงานจำนวนมากที่สุดได้แก่:\n",
      "\n",
      "1. การขายส่งและการขายปลีก, การซ่อมยานยนต์และรถจักรยานยนต์\n",
      "2. กิจกรรมการบริหารและสนับสนุน\n",
      "\n",
      "## การเปลี่ยนแปลงของการเข้าออกงาน\n",
      "\n",
      "เมื่อเทียบกับการเข้างาน, การผลิตมีจำนวนผู้ออกจากงานเท่ากัน.\n",
      "\n",
      "Reference(s):\n",
      "[1] รายงานผลการวิเคราะห์ข้อมูลอุปสงค์และอุปทานแรงงาน จังหวัดปทุมธานี พ.ศ. 2566, ตารางที่ 21.\n",
      "Answer: # แรงงานออกจากงานในจังหวัดปทุมธานี\n",
      "\n",
      "## จำนวนแรงงานออกจากงาน\n",
      "\n",
      "จำนวนแรงงานที่ออกจากงานมากที่สุดอยู่ในระดับวุฒิการศึกษาระดับต่ำกว่ามัธยมศึกษาปีที่ 3, มัธยมศึกษาปีที่ 3, และปริญญาตรี ตามลำดับ.\n",
      "\n",
      "## ประเภทอุตสาหกรรมที่มีการออกจากงานจำนวนมากที่สุด\n",
      "\n",
      "ประเภทอุตสาหกรรมที่มีการออกจากงานจำนวนมากที่สุดได้แก่:\n",
      "\n",
      "1. การขายส่งและการขายปลีก, การซ่อมยานยนต์และรถจักรยานยนต์\n",
      "2. กิจกรรมการบริหารและสนับสนุน\n",
      "\n",
      "## การเปลี่ยนแปลงของการเข้าออกงาน\n",
      "\n",
      "เมื่อเทียบกับการเข้างาน, การผลิตมีจำนวนผู้ออกจากงานเท่ากัน.\n",
      "\n",
      "Reference(s):\n",
      "[1] รายงานผลการวิเคราะห์ข้อมูลอุปสงค์และอุปทานแรงงาน จังหวัดปทุมธานี พ.ศ. 2566, ตารางที่ 21.\n",
      "Answer: # แรงงานออกจากงานในจังหวัดปทุมธานี\n",
      "\n",
      "## จำนวนแรงงานออกจากงาน\n",
      "\n",
      "จำนวนแรงงานที่ออกจากงานมากที่สุดอยู่ในระดับวุฒิการศึกษาระดับต่ำกว่ามัธยมศึกษาปีที่ 3, มัธยมศึกษาปีที่ 3, และปริญญาตรี ตามลำดับ.\n",
      "\n",
      "## ประเภทอุตสาหกรรมที่มีการออกจากงานจำนวนมากที่สุด\n",
      "\n",
      "ประเภทอุตสาหกรรมที่มีการออกจากงานจำนวนมากที่สุดได้แก่:\n",
      "\n",
      "1. การขายส่งและการขายปลีก, การซ่อมยานยนต์และรถจักรยานยนต์\n",
      "2. กิจกรรมการบริหารและสนับสนุน\n",
      "\n",
      "## การเปลี่ยนแปลงของการเข้าออกงาน\n",
      "\n",
      "เมื่อเทียบกับการเข้างาน, การผลิตมีจำนวนผู้ออกจากงานเท่ากัน.\n",
      "\n",
      "Reference(s):\n",
      "[1] รายงานผลการวิเคราะห์ข้อมูลอุปสงค์และอุปทานแรงงาน จังหวัดปทุมธานี พ.ศ. 2566, ตารางที่ 21.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    memory = ConversationalMemory(max_length=10)\n",
    "    memory_file = \"conversation_memory.json\"\n",
    "    memory.load_memory_from_file(memory_file)\n",
    "\n",
    "    while True:\n",
    "        question = input(\"Enter your question: \")\n",
    "        if question.lower() == \"exit\":\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        response = ask_question_with_memory(retriever, question, memory)\n",
    "        print(f\"Answer: {response}\")\n",
    "    memory.save_memory_to_file(memory_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "model = BGEM3FlagModel('BAAI/bge-m3',  \n",
    "                       use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.62590337 0.34749585]\n",
      " [0.34986818 0.6782464 ]]\n"
     ]
    }
   ],
   "source": [
    "sentences_1 = [\"What is BGE M3?\", \"Defination of BM25\"]\n",
    "sentences_2 = [\"BGE M3 is an embedding model supporting dense retrieval, lexical matching and multi-vector interaction.\", \n",
    "               \"BM25 is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document\"]\n",
    "\n",
    "embeddings_1 = model.encode(sentences_1, \n",
    "                            batch_size=12, \n",
    "                            max_length=8192,\n",
    "                            )['dense_vecs']\n",
    "embeddings_2 = model.encode(sentences_2)['dense_vecs']\n",
    "similarity = embeddings_1 @ embeddings_2.T\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-readers-faiss in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-readers-faiss) (0.12.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (3.11.2)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (2024.3.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (10.4.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (1.17.1)\n",
      "Requirement already satisfied: click in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (3.23.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\kongl\\documents\\dsi314 progress 2\\dsi314\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-faiss) (23.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-readers-faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved vectors: \n",
      "[[-0.00677118  0.02276473 -0.00233496 ...  0.02569435  0.02762516\n",
      "  -0.01567653]\n",
      " [ 0.03025599  0.05168479 -0.02412735 ...  0.0234941   0.00523008\n",
      "  -0.05033495]\n",
      " [-0.017729    0.02841178 -0.03170023 ...  0.02352753  0.01174562\n",
      "  -0.06735812]\n",
      " ...\n",
      " [-0.03484033  0.02584333 -0.02750481 ...  0.03353063 -0.00916356\n",
      "  -0.07829966]\n",
      " [-0.02960305  0.01953099 -0.00545851 ...  0.00705053 -0.01074381\n",
      "  -0.04163727]\n",
      " [-0.07328457  0.00565345 -0.01656812 ... -0.01026038  0.01278077\n",
      "  -0.02600808]]\n",
      "Search results (distances): [[341.71185 341.82825 341.97366 342.00555 342.0192 ]]\n",
      "\n",
      "Corresponding Document IDs for the search results:\n",
      "Index 409 -> Document ID: Document ID 409\n",
      "Index 1092 -> Document ID: Document ID 1092\n",
      "Index 64 -> Document ID: Document ID 64\n",
      "Index 480 -> Document ID: Document ID 480\n",
      "Index 2314 -> Document ID: Document ID 2314\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "faiss_index_path = 'Data/faiss_index/index.faiss'\n",
    "index = faiss.read_index(faiss_index_path)\n",
    "num_vectors_to_retrieve = 10\n",
    "vectors = []\n",
    "\n",
    "for i in range(num_vectors_to_retrieve):\n",
    "    vector = index.reconstruct(i)\n",
    "    vectors.append(vector)\n",
    "\n",
    "vectors = np.array(vectors)\n",
    "print(f\"Retrieved vectors: \\n{vectors}\")\n",
    "\n",
    "query_vector = np.random.rand(index.d).astype(np.float32) \n",
    "\n",
    "k = 5\n",
    "\n",
    "distances, indices = index.search(np.array([query_vector]), k)\n",
    "print(f\"Search results (distances): {distances}\")\n",
    "id_to_text_map = {i: f\"Document ID {i}\" for i in range(index.ntotal)}\n",
    "print(\"\\nCorresponding Document IDs for the search results:\")\n",
    "for idx in indices[0]:\n",
    "    doc_id = id_to_text_map.get(idx, \"Unknown Document ID\")\n",
    "    print(f\"Index {idx} -> Document ID: {doc_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DSI314",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
